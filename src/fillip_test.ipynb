{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:03:01.982068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 18:03:02.005488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 18:03:02.014820: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 18:03:02.030488: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 18:03:03.713007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9834, 400) (9834,)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load('../data/dataset.npz',)\n",
    "X, y = dataset['X'], dataset['y']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axis = plt.subplots(17, 5, figsize=(12, 48))\n",
    "\n",
    "# for label in range(17):\n",
    "#     for i in range(5):\n",
    "#         axis[label, i].imshow(X[y == label][i+5].reshape(20, 20), vmin=0, vmax=255, cmap='gray')\n",
    "#         axis[label, i].set_xticks([])\n",
    "#         axis[label, i].set_yticks([])\n",
    "#         axis[label, i].set_title(f'Label {label}')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 627\n",
      "Label 1: 230\n",
      "Label 2: 525\n",
      "Label 3: 950\n",
      "Label 4: 500\n",
      "Label 5: 695\n",
      "Label 6: 912\n",
      "Label 7: 605\n",
      "Label 8: 427\n",
      "Label 9: 205\n",
      "Label 10: 825\n",
      "Label 11: 525\n",
      "Label 12: 950\n",
      "Label 13: 909\n",
      "Label 14: 74\n",
      "Label 15: 450\n",
      "Label 16: 425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(17):\n",
    "    print(f'Label {i}: {len(X[y == i])}')\n",
    "\n",
    "max([len(X[y == i]) for i in range(17)]) * 17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=seed, k_neighbors=2)\n",
    "# X_res, y_res = sm.fit_resample(X.reshape(X.shape[0], -1), y)\n",
    "# print(X_res.shape, y_res.shape)\n",
    "\n",
    "# #fig, axis = plt.subplots(17, 5, figsize=(12, 48))\n",
    "# for label in range(17):\n",
    "#     for i in range(5):\n",
    "#         axis[label, i].imshow(X_res[y_res == label][949-i].reshape(20, 20), vmin=0, vmax=255, cmap='gray')\n",
    "#         axis[label, i].set_xticks([])\n",
    "#         axis[label, i].set_yticks([])\n",
    "#         axis[label, i].set_title(f'Label {label}')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9834, 400) (9834,)\n",
      "(5, 400) (5,)\n"
     ]
    }
   ],
   "source": [
    "def generate_label(X, y, label, n):\n",
    "    \"\"\"generates n augmented images for a given label\"\"\"\n",
    "    X = X[y == label]\n",
    "    y = y[y == label]\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    X_reshaped = X.reshape(X.shape[0], 20, 20, 1)\n",
    "\n",
    "    augmented_data = datagen.flow(X_reshaped, y, batch_size=1, seed=seed)\n",
    "    X_augs, y_augs = [], []\n",
    "    for i in range(n):\n",
    "        X_aug, y_aug = augmented_data.__next__()\n",
    "        X_aug = X_aug.flatten()\n",
    "        X_augs.append(X_aug)\n",
    "        y_augs.append(y_aug)\n",
    "    \n",
    "    X_augs = np.array(X_augs)\n",
    "    y_augs = np.array(y_augs).reshape(-1)\n",
    "\n",
    "    return np.array(X_augs), np.array(y_augs)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "X_aug, y_aug = generate_label(X, y, 1, 5)\n",
    "print(X_aug.shape, y_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16150, 400) (16150,)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import generate_balanced_data\n",
    "\n",
    "X_aug, y_aug = generate_balanced_data(X, y, 42)\n",
    "\n",
    "print(X_aug.shape, y_aug.shape)\n",
    "# fig, axis = plt.subplots(17, 5, figsize=(12, 48))\n",
    "\n",
    "# for label in range(0,17):\n",
    "#     for i in range(5):\n",
    "#         axis[label, i].imshow(X_aug[y_aug == label][i].reshape(20, 20), vmin=0, vmax=255, cmap='gray')\n",
    "#         axis[label, i].set_xticks([])\n",
    "#         axis[label, i].set_yticks([])\n",
    "#         axis[label, i].set_title(f'Label {label}')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(935, 400)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load('../data/corrupt_dataset.npz',)\n",
    "CX = dataset['X']\n",
    "print(CX.shape)\n",
    "# fig, axis = plt.subplots(17, 5, figsize=(12, 48))\n",
    "\n",
    "# for label in range(0,17):\n",
    "#     for i in range(5):\n",
    "#         axis[label, i].imshow(X[i+label+5].reshape(20, 20), vmin=0, vmax=255, cmap='gray')\n",
    "#         axis[label, i].set_xticks([])\n",
    "#         axis[label, i].set_yticks([])\n",
    "#         axis[label, i].set_title(f'Label {label}')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, numChannels, classes):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        #scales it down to 18x18 x 20\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=numChannels, \n",
    "            out_channels=20,\n",
    "            kernel_size=(3,3), \n",
    "            )\n",
    "        \n",
    "        #first relu pass\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        #scales it down to 9x9 x 20\n",
    "        self.maxpool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2,2),\n",
    "            stride=(2,2)\n",
    "            )\n",
    "\n",
    "        #scales it down to 7x7 x 50 \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=20, \n",
    "            out_channels=50,\n",
    "            kernel_size=(3,3), \n",
    "            )\n",
    "\n",
    "        #second relu pass\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        #scales it down to 3x3 x 50\n",
    "        self.maxpool2 = nn.MaxPool2d(\n",
    "            kernel_size=(2,2),\n",
    "            stride=(2,2),\n",
    "            )\n",
    "\n",
    "        #takes the 3x3x50 = 450\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=450,\n",
    "            out_features=500,\n",
    "            )\n",
    "        \n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=500,\n",
    "            out_features=classes,\n",
    "        )\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        output = self.logsoftmax(x)\n",
    "        return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "TRAIN_SPLIT = 0.70\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the network now\n",
      "Epoch 1/10\n",
      "Train loss: 0.0448, Train accuracy: 0.6831\n",
      "Val loss: 0.0150, Val accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "Train loss: 0.0117, Train accuracy: 0.8796\n",
      "Val loss: 0.0122, Val accuracy: 0.8803\n",
      "Epoch 3/10\n",
      "Train loss: 0.0079, Train accuracy: 0.9194\n",
      "Val loss: 0.0104, Val accuracy: 0.8993\n",
      "Epoch 4/10\n",
      "Train loss: 0.0059, Train accuracy: 0.9373\n",
      "Val loss: 0.0085, Val accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "Train loss: 0.0042, Train accuracy: 0.9532\n",
      "Val loss: 0.0093, Val accuracy: 0.9137\n",
      "Epoch 6/10\n",
      "Train loss: 0.0037, Train accuracy: 0.9612\n",
      "Val loss: 0.0084, Val accuracy: 0.9261\n",
      "Epoch 7/10\n",
      "Train loss: 0.0031, Train accuracy: 0.9651\n",
      "Val loss: 0.0087, Val accuracy: 0.9249\n",
      "Epoch 8/10\n",
      "Train loss: 0.0026, Train accuracy: 0.9710\n",
      "Val loss: 0.0099, Val accuracy: 0.9179\n",
      "Epoch 9/10\n",
      "Train loss: 0.0027, Train accuracy: 0.9716\n",
      "Val loss: 0.0083, Val accuracy: 0.9331\n",
      "Epoch 10/10\n",
      "Train loss: 0.0020, Train accuracy: 0.9775\n",
      "Val loss: 0.0104, Val accuracy: 0.9241\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "    X_aug, \n",
    "    y_aug, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=seed\n",
    "    )\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test, \n",
    "    y_val_test, \n",
    "    test_size=0.5, \n",
    "    random_state=seed\n",
    "    )\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "model = LeNet(numChannels=1, classes=17).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=INIT_LR)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "H = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"training the network now\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    correct_train = 0\n",
    "    correct_val = 0\n",
    "\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch = X_batch.view(X_batch.size(0), 1, 20, 20)  # Reshape the input tensor\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        correct_train += (y_pred.argmax(1) == y_batch).type(torch.float).sum().item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch = X_val_batch.view(X_val_batch.size(0), 1, 20, 20)\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            loss = criterion(y_val_pred, y_val_batch)\n",
    "            total_val_loss += loss.item()\n",
    "            correct_val += (y_val_pred.argmax(1) == y_val_batch).type(torch.float).sum().item()\n",
    "        \n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "    avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "    train_acc = correct_train / len(train_loader.dataset)\n",
    "    val_acc = correct_val / len(val_loader.dataset)\n",
    "\n",
    "    H['train_loss'].append(avg_train_loss)\n",
    "    H['val_loss'].append(avg_val_loss)\n",
    "    H['train_acc'].append(train_acc)\n",
    "    H['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train loss: {avg_train_loss:.4f}, Train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val loss: {avg_val_loss:.4f}, Val accuracy: {val_acc:.4f}\")\n",
    "\n",
    "print(\"training complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       140\n",
      "           1       0.86      1.00      0.92       136\n",
      "           2       0.89      0.94      0.91       146\n",
      "           3       0.99      0.90      0.95       164\n",
      "           4       0.94      0.93      0.93       153\n",
      "           5       0.92      0.95      0.94       138\n",
      "           6       0.99      0.97      0.98       145\n",
      "           7       0.92      0.96      0.94       137\n",
      "           8       0.90      0.84      0.87       129\n",
      "           9       0.92      0.92      0.92       147\n",
      "          10       0.90      0.93      0.91       157\n",
      "          11       0.88      0.91      0.90       151\n",
      "          12       0.96      0.98      0.97       137\n",
      "          13       0.95      0.87      0.91       132\n",
      "          14       0.95      0.81      0.87       128\n",
      "          15       0.89      0.85      0.87       139\n",
      "          16       1.00      1.00      1.00       144\n",
      "\n",
      "    accuracy                           0.92      2423\n",
      "   macro avg       0.93      0.92      0.92      2423\n",
      "weighted avg       0.93      0.92      0.92      2423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.view(X_batch.size(0), 1, 20, 20)\n",
    "        y_pred = model(X_batch)\n",
    "        preds.append(y_pred.argmax(1))\n",
    "\n",
    "    preds = torch.cat(preds).cpu().numpy()\n",
    "\n",
    "print(classification_report(y_test.cpu().numpy(), preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
